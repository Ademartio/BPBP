{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qecsim.models.rotatedplanar import RotatedPlanarCode\n",
    "from ldpc import bp_decoder\n",
    "import numpy as np\n",
    "import random\n",
    "from qecsim import paulitools as pt\n",
    "# from networkx import find_cycle\n",
    "import networkx as nt\n",
    "from copy import deepcopy\n",
    "from ldpc import bposd_decoder\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_generation(p, n):\n",
    "    \"\"\"Depolarizing error generation\n",
    "\n",
    "    Args:\n",
    "        p (float): Probability of error\n",
    "        n (int): number of qubits\n",
    "    \"\"\"\n",
    "    error = np.zeros(2*n)\n",
    "    probabilities = [(1 - p), p/3, p/3, p/3]\n",
    "    results = ['I', 'X', 'Y', 'Z']\n",
    "\n",
    "    # Generate n random realizations based on the probabilities\n",
    "    realizations = random.choices(results, probabilities, k=n)\n",
    "    for index, realization in enumerate(realizations):\n",
    "        if realization == 'X':\n",
    "            error[index] = 1\n",
    "        elif realization == 'Z':\n",
    "            error[index+n] = 1\n",
    "        elif realization == 'Y':\n",
    "            error[index] = 1\n",
    "            error[index+n] = 1\n",
    "    return error.astype(int)\n",
    "\n",
    "def order_matrix_by_vector(vector, matrix):\n",
    "    # Sort the indices of the vector based on its values\n",
    "    sorted_indices = np.argsort(vector)\n",
    "    # Reorder the columns of the matrix based on the sorted indices\n",
    "    ordered_matrix = matrix[:, sorted_indices]\n",
    "    return ordered_matrix, sorted_indices\n",
    "\n",
    "\n",
    "def kruskal_on_hypergraph(Hog):\n",
    "    \"\"\"\n",
    "    We now need to produce the Tanner graph via nt.graph\n",
    "\n",
    "    In contination follow the following route:\n",
    "    1 add first hyperedge to the graph as different hyperedges\n",
    "    2 initiate following loop:\n",
    "    initial_graph = nt.graph()\n",
    "    for column in H:\n",
    "        graph_to_try = initial_graph.copy()\n",
    "        for i in np.where(H[:,column]==0):\n",
    "            graph_to_try.add_edge((i+H.shape[1],column))\n",
    "        if graph_to_try.has_loops():\n",
    "            continue\n",
    "        else:\n",
    "            initial_graph = graph_to_try.copy()\n",
    "            # Checkear que no hayan ya m√°s de n-k columnas\n",
    "            \n",
    "     \"\"\"\n",
    "     \n",
    "    initial_graph = nt.Graph()\n",
    "    rows, columns = Hog.shape\n",
    "    column_to_square = np.zeros(rows)\n",
    "    \n",
    "    # Just before initializing the process we introduce two additional rows on H, introducing virtual checks.\n",
    "    zeros_rows = np.zeros((2, columns))\n",
    "    H =  np.vstack((Hog, zeros_rows))\n",
    "    \n",
    "    \n",
    "    for i in range(columns):\n",
    "        if len(np.where(H[:,i] == 1)[0]) == 1:\n",
    "            if np.where(H[:,i] == 1)[0][0] < rows:\n",
    "                H[-2,i] = 1\n",
    "            else:\n",
    "                H[-1,i] = 1\n",
    "                \n",
    "    \n",
    "    column_number = 1\n",
    "    # Rows (Checks) are numbers 0 to rows-1\n",
    "    # Columns (hypergraphs) are numbers rows-1 to rows+columns-1\n",
    "    # column_to_square is a vector with the columns that will be considered for the square matrix:\n",
    "    # final_matrix = H[:, column_to_square]\n",
    "    \n",
    "    # We begin by adding the first column:\n",
    "    for edge in np.where(H[:,0] == 1)[0]:\n",
    "        initial_graph.add_edge(edge, rows+2)\n",
    "    \n",
    "    \n",
    "    for i in range(1,columns):\n",
    "        # column_to_consider = H[:,i]\n",
    "        \n",
    "        Graph_to_check = deepcopy(initial_graph)\n",
    "        # edges_to_add = []\n",
    "        for edge in np.where(H[:,i] == 1)[0]:\n",
    "            # edges_to_add.append((edge, i+rows+2))\n",
    "            Graph_to_check.add_edge(edge, i+rows+2)\n",
    "        # initial_graph.add_edges_from(edges_to_add)\n",
    "        # if len(list(nt.simple_cycles(initial_graph))) > 0:\n",
    "        if len(list(nt.simple_cycles(Graph_to_check))) > 0:\n",
    "            # initial_graph.remove_edges_from(edges_to_add)\n",
    "            continue\n",
    "        initial_graph = Graph_to_check\n",
    "        column_to_square[column_number] = i\n",
    "        column_number += 1\n",
    "        if column_number == rows:\n",
    "            break\n",
    "    \n",
    "\n",
    "    assert column_to_square[-1] != 0, \" Ha habido un error, no ha encontrado n-k columnas independientes\"\n",
    "    \n",
    "    H_square = H[:,column_to_square.astype(int)]\n",
    "    \n",
    "    empty_column = np.zeros((H_square.shape[0], 1))  # Create an empty column filled with zeros\n",
    "    matrix_with_empty_column = np.hstack((H_square, empty_column))\n",
    "\n",
    "    return matrix_with_empty_column[:-2,:], column_to_square\n",
    "    \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 3\n",
      "-------------------------------------------------\n",
      "Physical error: 0.01\n",
      "Error BP: 0.05220000000000047\n",
      "Error BPOSD: 0.0017000000000000006\n",
      "Error BPBP: 0.0017000000000000006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m llrs \u001b[38;5;241m=\u001b[39m _bp\u001b[38;5;241m.\u001b[39mlog_prob_ratios\n\u001b[0;32m     62\u001b[0m ordered_pcm, sorted_indices \u001b[38;5;241m=\u001b[39m order_matrix_by_vector(llrs, pcm)\n\u001b[1;32m---> 63\u001b[0m pcm_squared, columns_chosen \u001b[38;5;241m=\u001b[39m \u001b[43mkruskal_on_hypergraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mordered_pcm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m _bp_squared \u001b[38;5;241m=\u001b[39m bp_decoder(\n\u001b[0;32m     66\u001b[0m     pcm_squared,\n\u001b[0;32m     67\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m     68\u001b[0m     error_rate \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     71\u001b[0m second_recovered_error \u001b[38;5;241m=\u001b[39m _bp_squared\u001b[38;5;241m.\u001b[39mdecode(syndrome)\n",
      "Cell \u001b[1;32mIn[8], line 90\u001b[0m, in \u001b[0;36mkruskal_on_hypergraph\u001b[1;34m(Hog)\u001b[0m\n\u001b[0;32m     87\u001b[0m     Graph_to_check\u001b[38;5;241m.\u001b[39madd_edge(edge, i\u001b[38;5;241m+\u001b[39mrows\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# initial_graph.add_edges_from(edges_to_add)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# if len(list(nt.simple_cycles(initial_graph))) > 0:\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(nt\u001b[38;5;241m.\u001b[39msimple_cycles(Graph_to_check))) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# initial_graph.remove_edges_from(edges_to_add)\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     93\u001b[0m initial_graph \u001b[38;5;241m=\u001b[39m Graph_to_check\n",
      "File \u001b[1;32mc:\\Users\\tonid\\anaconda3\\envs\\cb_environment\\Lib\\site-packages\\networkx\\algorithms\\cycles.py:222\u001b[0m, in \u001b[0;36msimple_cycles\u001b[1;34m(G, length_bound)\u001b[0m\n\u001b[0;32m    220\u001b[0m     G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mDiGraph((u, v) \u001b[38;5;28;01mfor\u001b[39;00m u, Gu \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39madj\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m Gu \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m!=\u001b[39m u)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     G \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mGu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# this case is not strictly necessary but improves performance\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length_bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m length_bound \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tonid\\anaconda3\\envs\\cb_environment\\Lib\\site-packages\\networkx\\classes\\graph.py:371\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[1;34m(self, incoming_graph_data, **attr)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# attempt to load graph with data\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incoming_graph_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 371\u001b[0m     \u001b[43mconvert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_networkx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincoming_graph_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_using\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# load graph attributes (must be after convert)\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mupdate(attr)\n",
      "File \u001b[1;32mc:\\Users\\tonid\\anaconda3\\envs\\cb_environment\\Lib\\site-packages\\networkx\\convert.py:118\u001b[0m, in \u001b[0;36mto_networkx_graph\u001b[1;34m(data, create_using, multigraph_input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Pandas DataFrame\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1138\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1078\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1504\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1476\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1612\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# distances = [3]\n",
    "distances = [3,5, 7, 9]\n",
    "NMCs = [10**4, 10**4, 10**4, 10**4, 10**4, 10**4, 10**4, 10**4, 10**4, 10**3, 10**3, 10**3, 10**3]\n",
    "ps = np.linspace(0.01, 0.13, num=13)\n",
    "PlsBP = {}\n",
    "PlsBPOSD = {}\n",
    "PlsBPBP = {}\n",
    "\n",
    "for distance in distances:\n",
    "    myCode = RotatedPlanarCode(distance, distance)\n",
    "    pcm = np.zeros((myCode.stabilizers.shape[0], myCode.stabilizers.shape[1]), dtype = int)\n",
    "\n",
    "    pcm[:,:pcm.shape[1]//2] = myCode.stabilizers[:,pcm.shape[1]//2:]\n",
    "    pcm[:,pcm.shape[1]//2:] = myCode.stabilizers[:,:pcm.shape[1]//2]\n",
    "    \n",
    "    PlsBP[distance] = []\n",
    "    PlsBPBP[distance] = []\n",
    "    PlsBPOSD[distance] = []\n",
    "    print(f'Distance: {distance}')\n",
    "    print('-------------------------------------------------')\n",
    "    for index, p in enumerate(ps):\n",
    "    \n",
    "        _bp = bp_decoder(\n",
    "            pcm,\n",
    "            max_iter=30,\n",
    "            error_rate = p\n",
    "        )\n",
    "        \n",
    "        _bposd = bposd_decoder(\n",
    "            pcm,\n",
    "            max_iter=30,\n",
    "            error_rate = p,\n",
    "            osd_method = \"osd_0\"\n",
    "        )\n",
    "        \n",
    "        PlBP = 0\n",
    "        PlBPBP = 0\n",
    "        PlBPOSD = 0\n",
    "        \n",
    "        for iteration in range(NMCs[index]):\n",
    "            error = error_generation(p, myCode.n_k_d[0])\n",
    "            syndrome = pt.bsp(error, myCode.stabilizers.T)\n",
    "            # syndrome = pt.bsp(error, pcm.T)\n",
    "            # BPOSD decoder\n",
    "            #----------------------------\n",
    "            recovered_error_BPOSD = _bposd.decode(syndrome)\n",
    "            if np.any(pt.bsp(recovered_error_BPOSD ^ error, myCode.logicals.T) == 1):\n",
    "                PlBPOSD += 1/NMCs[index]\n",
    "            #----------------------------\n",
    "            \n",
    "            recovered_error = _bp.decode(syndrome)\n",
    "            if _bp.converge:\n",
    "                if np.any(pt.bsp(recovered_error ^ error, myCode.logicals.T) == 1):\n",
    "                    PlBP += 1/NMCs[index]\n",
    "                    PlBPBP += 1/NMCs[index]\n",
    "                continue\n",
    "            else:\n",
    "                PlBP += 1/NMCs[index]\n",
    "\n",
    "            llrs = _bp.log_prob_ratios\n",
    "\n",
    "            ordered_pcm, sorted_indices = order_matrix_by_vector(llrs, pcm)\n",
    "            pcm_squared, columns_chosen = kruskal_on_hypergraph(ordered_pcm)\n",
    "            \n",
    "            _bp_squared = bp_decoder(\n",
    "                pcm_squared,\n",
    "                max_iter=30,\n",
    "                error_rate = p\n",
    "            )\n",
    "            \n",
    "            second_recovered_error = _bp_squared.decode(syndrome)\n",
    "        \n",
    "            if _bp_squared.converge:\n",
    "                non_trivials = sorted_indices[columns_chosen[np.where(second_recovered_error == 1)[0]].astype(int)]\n",
    "                second_recovered_error_n = np.zeros(2*myCode.n_k_d[0])\n",
    "                second_recovered_error_n[non_trivials] = 1\n",
    "                if np.any(pt.bsp(second_recovered_error_n.astype(int) ^ error, myCode.logicals.T) == 1):\n",
    "                    PlBPBP += 1/NMCs[index]\n",
    "                    \n",
    "            else:\n",
    "                PlBPBP += 1/NMCs[index]\n",
    "                continue\n",
    "            \n",
    "        \n",
    "        PlsBP[distance].append(PlBP)\n",
    "        PlsBPOSD[distance].append(PlBPOSD)\n",
    "        PlsBPBP[distance].append(PlBPBP)\n",
    "            \n",
    "        print(f'Physical error: {p}')\n",
    "        print(f'Error BP: {PlBP}')\n",
    "        print(f'Error BPOSD: {PlBPOSD}')\n",
    "        print(f'Error BPBP: {PlBPBP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
